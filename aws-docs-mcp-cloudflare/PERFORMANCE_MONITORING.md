# ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•å’Œç›‘æ§æ–¹æ¡ˆ

## ğŸ¯ æ€§èƒ½ç›®æ ‡ä¸åŸºå‡†

### æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ç±»åˆ« | åŸºå‡†å€¼ | ç›®æ ‡å€¼ | ä¼˜ç§€å€¼ | æµ‹é‡æ–¹å¼ |
|---------|--------|--------|--------|----------|
| **å“åº”å»¶è¿Ÿ** | <200ms (P95) | <100ms (P95) | <50ms (P95) | HTTPå“åº”æ—¶é—´ |
| **ååé‡** | >1,000 QPS | >10,000 QPS | >50,000 QPS | æ¯ç§’è¯·æ±‚æ•° |
| **å¯ç”¨æ€§** | >99.9% | >99.95% | >99.99% | æ­£å¸¸å“åº”ç‡ |
| **é”™è¯¯ç‡** | <0.1% | <0.01% | <0.001% | é”™è¯¯è¯·æ±‚æ¯”ä¾‹ |
| **å¹¶å‘è¿æ¥** | >100 | >1,000 | >10,000 | åŒæ—¶SSEè¿æ¥ |

### æ€§èƒ½å¯¹æ¯”åŸºå‡†

```yaml
# STDIO vs SSE æ€§èƒ½å¯¹æ¯”åŸºå‡†
STDIOåŸç‰ˆ (æœ¬åœ°):
  å»¶è¿Ÿ: 50-200ms (æœ¬åœ°ç½‘ç»œ)
  ååé‡: 10-50 QPS (å•çº¿ç¨‹é™åˆ¶)
  å¹¶å‘: 1ä¸ªè¿æ¥
  å¯ç”¨æ€§: 99% (å•ç‚¹æ•…éšœ)
  
SSEæ–°ç‰ˆ (Cloudflare):
  å»¶è¿Ÿ: 30-100ms (å…¨çƒè¾¹ç¼˜)
  ååé‡: 10,000+ QPS (æ— é™æ‰©ç¼©)
  å¹¶å‘: 10,000+ è¿æ¥
  å¯ç”¨æ€§: 99.99% (è¾¹ç¼˜å†—ä½™)
  
æ€§èƒ½æå‡:
  å»¶è¿Ÿ: é™ä½50-75%
  ååé‡: æå‡200-1000å€
  å¹¶å‘: æå‡10,000å€
  å¯ç”¨æ€§: æå‡99å€
```

## ğŸ§ª æ€§èƒ½æµ‹è¯•æ–¹æ¡ˆ

### æµ‹è¯•ç¯å¢ƒé…ç½®

```yaml
æµ‹è¯•å·¥å…·æ ˆ:
  è´Ÿè½½æµ‹è¯•: k6, Artillery, wrk
  ç›‘æ§å·¥å…·: Grafana, DataDog, New Relic
  åˆ†æå·¥å…·: Lighthouse, WebPageTest
  å‹æµ‹å¹³å°: AWS Load Testing, Cloudflare Analytics

æµ‹è¯•ç¯å¢ƒ:
  - æœ¬åœ°å¼€å‘ç¯å¢ƒ (åŸºç¡€æµ‹è¯•)
  - Cloudflareæµ‹è¯•ç¯å¢ƒ (é›†æˆæµ‹è¯•)
  - å¤šåŒºåŸŸåˆ†å¸ƒå¼æµ‹è¯• (å…¨çƒæ€§èƒ½)
  - ç”Ÿäº§ç¯å¢ƒé•œåƒ (çœŸå®æ€§èƒ½)
```

### åŸºå‡†æµ‹è¯•å¥—ä»¶

```bash
#!/bin/bash
# performance-benchmark.sh - ç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•

BASE_URL=${1:-https://aws-docs-mcp-server.workers.dev}
OUTPUT_DIR="performance-reports"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

mkdir -p $OUTPUT_DIR

echo "ğŸš€ å¼€å§‹æ€§èƒ½åŸºå‡†æµ‹è¯•: $BASE_URL"

# 1. åŸºç¡€å»¶è¿Ÿæµ‹è¯•
echo "ğŸ“Š æµ‹è¯•1: åŸºç¡€å“åº”å»¶è¿Ÿ"
k6 run --vus 1 --duration 30s \
  --out json=$OUTPUT_DIR/latency_$TIMESTAMP.json \
  tests/performance/latency-test.js

# 2. è´Ÿè½½å‹åŠ›æµ‹è¯•  
echo "ğŸ“Š æµ‹è¯•2: è´Ÿè½½å‹åŠ›æµ‹è¯•"
k6 run --vus 100 --duration 5m \
  --out json=$OUTPUT_DIR/load_$TIMESTAMP.json \
  tests/performance/load-test.js

# 3. çªå‘æµé‡æµ‹è¯•
echo "ğŸ“Š æµ‹è¯•3: çªå‘æµé‡æµ‹è¯•"
k6 run --stage 0s:0,30s:1000,1m:1000,30s:0 \
  --out json=$OUTPUT_DIR/spike_$TIMESTAMP.json \
  tests/performance/spike-test.js

# 4. é•¿æ—¶é—´ç¨³å®šæ€§æµ‹è¯•
echo "ğŸ“Š æµ‹è¯•4: é•¿æ—¶é—´ç¨³å®šæ€§"
k6 run --vus 50 --duration 30m \
  --out json=$OUTPUT_DIR/endurance_$TIMESTAMP.json \
  tests/performance/endurance-test.js

# 5. å…¨çƒå¤šç‚¹å»¶è¿Ÿæµ‹è¯•
echo "ğŸ“Š æµ‹è¯•5: å…¨çƒå»¶è¿Ÿåˆ†å¸ƒ"
./global-latency-test.sh $BASE_URL $OUTPUT_DIR

# 6. SSEè¿æ¥æ€§èƒ½æµ‹è¯•
echo "ğŸ“Š æµ‹è¯•6: SSEè¿æ¥æ€§èƒ½"
node tests/performance/sse-performance.js $BASE_URL > $OUTPUT_DIR/sse_$TIMESTAMP.json

# ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
echo "ğŸ“‹ ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š..."
node scripts/generate-perf-report.js $OUTPUT_DIR $TIMESTAMP

echo "âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ! æŠ¥å‘Šä½ç½®: $OUTPUT_DIR/report_$TIMESTAMP.html"
```

### ä¸“é¡¹æ€§èƒ½æµ‹è¯•

#### 1. AWSæ–‡æ¡£è¯»å–æ€§èƒ½æµ‹è¯•

```javascript
// tests/performance/doc-read-performance.js
import http from 'k6/http';
import { check } from 'k6';
import { Trend, Rate } from 'k6/metrics';

const docReadTime = new Trend('aws_doc_read_time', true);
const docReadSuccess = new Rate('aws_doc_read_success');

const testDocuments = [
  'https://docs.aws.amazon.com/ec2/latest/userguide/concepts.html',
  'https://docs.aws.amazon.com/s3/latest/userguide/Welcome.html',
  'https://docs.aws.amazon.com/lambda/latest/dg/welcome.html',
  'https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html',
  'https://docs.aws.amazon.com/rds/latest/userguide/Welcome.html'
];

export const options = {
  stages: [
    { duration: '2m', target: 10 },
    { duration: '5m', target: 10 },
    { duration: '1m', target: 0 },
  ],
  thresholds: {
    aws_doc_read_time: ['p(95)<5000'], // 95% under 5 seconds
    aws_doc_read_success: ['rate>0.95'], // 95% success rate
  },
};

export default function() {
  const testDoc = testDocuments[Math.floor(Math.random() * testDocuments.length)];
  
  const payload = JSON.stringify({
    jsonrpc: '2.0',
    id: `perf-test-${Date.now()}`,
    method: 'tools/call',
    params: {
      name: 'read_documentation',
      arguments: { url: testDoc }
    }
  });

  const params = {
    headers: { 'Content-Type': 'application/json' },
    timeout: '30s',
  };

  const startTime = Date.now();
  const response = http.post(`${__ENV.BASE_URL}/mcp/message`, payload, params);
  const duration = Date.now() - startTime;

  const success = check(response, {
    'status is 200': (r) => r.status === 200,
    'has content': (r) => {
      try {
        const body = JSON.parse(r.body);
        return body.result && body.result.content && body.result.content.length > 0;
      } catch {
        return false;
      }
    },
    'response time < 10s': () => duration < 10000,
  });

  docReadTime.add(duration);
  docReadSuccess.add(success);
}
```

#### 2. SSEè¿æ¥æ€§èƒ½æµ‹è¯•

```javascript
// tests/performance/sse-performance.js
const EventSource = require('eventsource');

async function testSSEPerformance(baseUrl, maxConnections = 100) {
  console.log(`ğŸ”— æµ‹è¯•SSEè¿æ¥æ€§èƒ½: ${maxConnections}ä¸ªå¹¶å‘è¿æ¥`);
  
  const connections = [];
  const metrics = {
    connectionTimes: [],
    messageLatencies: [],
    errors: 0,
    totalMessages: 0
  };

  // åˆ›å»ºå¤šä¸ªSSEè¿æ¥
  for (let i = 0; i < maxConnections; i++) {
    const startTime = Date.now();
    
    try {
      const es = new EventSource(`${baseUrl}/mcp/sse`);
      
      es.onopen = () => {
        const connectionTime = Date.now() - startTime;
        metrics.connectionTimes.push(connectionTime);
        console.log(`è¿æ¥ ${i + 1} å»ºç«‹: ${connectionTime}ms`);
      };

      es.onmessage = (event) => {
        const messageTime = Date.now();
        metrics.totalMessages++;
        
        try {
          const data = JSON.parse(event.data);
          if (data.timestamp) {
            const latency = messageTime - data.timestamp;
            metrics.messageLatencies.push(latency);
          }
        } catch (error) {
          // Ignore parsing errors
        }
      };

      es.onerror = () => {
        metrics.errors++;
      };

      connections.push(es);
      
      // æ§åˆ¶è¿æ¥å»ºç«‹é€Ÿç‡
      await new Promise(resolve => setTimeout(resolve, 50));
      
    } catch (error) {
      metrics.errors++;
      console.error(`è¿æ¥ ${i + 1} å¤±è´¥:`, error.message);
    }
  }

  // ç­‰å¾…è¿æ¥ç¨³å®š
  await new Promise(resolve => setTimeout(resolve, 30000));

  // å…³é—­æ‰€æœ‰è¿æ¥
  connections.forEach(es => es.close());

  // è®¡ç®—ç»Ÿè®¡æ•°æ®
  const stats = {
    totalConnections: maxConnections,
    successfulConnections: maxConnections - metrics.errors,
    averageConnectionTime: average(metrics.connectionTimes),
    p95ConnectionTime: percentile(metrics.connectionTimes, 95),
    averageMessageLatency: average(metrics.messageLatencies),
    totalMessages: metrics.totalMessages,
    errorRate: metrics.errors / maxConnections
  };

  console.log('ğŸ“Š SSEæ€§èƒ½æµ‹è¯•ç»“æœ:');
  console.log(`  æˆåŠŸè¿æ¥: ${stats.successfulConnections}/${stats.totalConnections}`);
  console.log(`  å¹³å‡è¿æ¥æ—¶é—´: ${stats.averageConnectionTime}ms`);
  console.log(`  P95è¿æ¥æ—¶é—´: ${stats.p95ConnectionTime}ms`);
  console.log(`  å¹³å‡æ¶ˆæ¯å»¶è¿Ÿ: ${stats.averageMessageLatency}ms`);
  console.log(`  æ€»æ¶ˆæ¯æ•°: ${stats.totalMessages}`);
  console.log(`  é”™è¯¯ç‡: ${(stats.errorRate * 100).toFixed(2)}%`);

  return stats;
}

function average(arr) {
  return arr.length ? arr.reduce((a, b) => a + b, 0) / arr.length : 0;
}

function percentile(arr, p) {
  if (!arr.length) return 0;
  const sorted = arr.sort((a, b) => a - b);
  const index = Math.ceil(sorted.length * p / 100) - 1;
  return sorted[index];
}

// è¿è¡Œæµ‹è¯•
if (require.main === module) {
  const baseUrl = process.argv[2] || 'http://localhost:8787';
  testSSEPerformance(baseUrl).catch(console.error);
}

module.exports = { testSSEPerformance };
```

#### 3. å…¨çƒå»¶è¿Ÿåˆ†å¸ƒæµ‹è¯•

```bash
#!/bin/bash
# global-latency-test.sh - å…¨çƒå¤šç‚¹å»¶è¿Ÿæµ‹è¯•

BASE_URL=$1
OUTPUT_DIR=$2

# å…¨çƒæµ‹è¯•èŠ‚ç‚¹ (ä½¿ç”¨DNS over HTTPSæµ‹è¯•ä¸åŒåœ°ç†ä½ç½®)
declare -A test_locations=(
  ["us-east"]="1.1.1.1"      # ç¾å›½ä¸œéƒ¨
  ["us-west"]="8.8.8.8"      # ç¾å›½è¥¿éƒ¨  
  ["eu-west"]="9.9.9.9"      # æ¬§æ´²è¥¿éƒ¨
  ["ap-southeast"]="208.67.222.222"  # äºšå¤ªä¸œå—
  ["ap-northeast"]="1.0.0.1" # äºšå¤ªä¸œåŒ—
)

echo "ğŸŒ å…¨çƒå»¶è¿Ÿåˆ†å¸ƒæµ‹è¯•"

for location in "${!test_locations[@]}"; do
  dns_server=${test_locations[$location]}
  echo "ğŸ“ æµ‹è¯•ä½ç½®: $location (DNS: $dns_server)"
  
  # ä½¿ç”¨curlæµ‹è¯•å»¶è¿Ÿ (æ¨¡æ‹Ÿä»ä¸åŒåœ°ç†ä½ç½®è®¿é—®)
  for i in {1..10}; do
    time=$(curl -w "%{time_total}" -o /dev/null -s --dns-servers $dns_server "$BASE_URL/health")
    echo "$location,$time" >> "$OUTPUT_DIR/global_latency.csv"
  done
done

# ç”Ÿæˆå»¶è¿Ÿåˆ†å¸ƒæŠ¥å‘Š
cat "$OUTPUT_DIR/global_latency.csv" | \
awk -F',' '{
  location[$1] += $2; 
  count[$1]++
} 
END {
  for (loc in location) {
    avg = location[loc] / count[loc] * 1000;
    printf "%-15s: %.2f ms\n", loc, avg
  }
}' > "$OUTPUT_DIR/global_latency_summary.txt"

echo "âœ… å…¨çƒå»¶è¿Ÿæµ‹è¯•å®Œæˆ"
```

## ğŸ“ˆ å®æ—¶ç›‘æ§ç³»ç»Ÿ

### Cloudflare Analyticsé›†æˆ

```typescript
// src/monitoring.ts - ç›‘æ§ä¸­é—´ä»¶
export class PerformanceMonitor {
  private metrics = new Map();
  
  middleware() {
    return async (c: Context, next: () => Promise<void>) => {
      const startTime = Date.now();
      const requestId = c.req.header('cf-ray') || generateId();
      
      try {
        await next();
        
        const duration = Date.now() - startTime;
        const status = c.res.status;
        
        // è®°å½•æ€§èƒ½æŒ‡æ ‡
        this.recordMetric('request_duration', duration, {
          method: c.req.method,
          path: c.req.path,
          status: status.toString()
        });
        
        // è®°å½•å“åº”å¤´
        c.header('X-Response-Time', `${duration}ms`);
        c.header('X-Request-ID', requestId);
        
        // è®°å½•åˆ°Cloudflare Analytics
        this.sendToAnalytics({
          timestamp: Date.now(),
          requestId,
          method: c.req.method,
          path: c.req.path,
          status,
          duration,
          userAgent: c.req.header('user-agent'),
          country: c.req.header('cf-ipcountry'),
          colo: c.req.header('cf-colo')
        });
        
      } catch (error) {
        const duration = Date.now() - startTime;
        
        this.recordMetric('request_error', 1, {
          method: c.req.method,
          path: c.req.path,
          error: error.message
        });
        
        throw error;
      }
    };
  }
  
  recordMetric(name: string, value: number, tags: Record<string, string> = {}) {
    const key = `${name}:${JSON.stringify(tags)}`;
    const current = this.metrics.get(key) || { count: 0, sum: 0, min: Infinity, max: -Infinity };
    
    current.count++;
    current.sum += value;
    current.min = Math.min(current.min, value);
    current.max = Math.max(current.max, value);
    current.avg = current.sum / current.count;
    current.last = value;
    current.lastUpdate = Date.now();
    
    this.metrics.set(key, current);
  }
  
  getMetrics() {
    const result = {};
    for (const [key, value] of this.metrics.entries()) {
      result[key] = value;
    }
    return result;
  }
  
  async sendToAnalytics(data: any) {
    // å‘é€åˆ°Cloudflare Analytics
    try {
      await fetch('https://cloudflare-analytics.com/v1/metrics', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.CF_ANALYTICS_TOKEN}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify(data)
      });
    } catch (error) {
      console.error('Failed to send analytics:', error);
    }
  }
}
```

### ç›‘æ§ä»ªè¡¨æ¿é…ç½®

```yaml
# grafana-dashboard.yml
dashboard:
  title: "AWS MCP Server Performance"
  tags: ["aws", "mcp", "cloudflare"]
  
  panels:
    - title: "Response Time"
      type: "graph"
      targets:
        - expr: "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))"
          legendFormat: "P95 Response Time"
        - expr: "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))"
          legendFormat: "P50 Response Time"
    
    - title: "Request Rate"
      type: "graph"
      targets:
        - expr: "rate(http_requests_total[5m])"
          legendFormat: "Requests per Second"
    
    - title: "Error Rate"
      type: "singlestat"
      targets:
        - expr: "rate(http_requests_total{status=~'5..'}[5m]) / rate(http_requests_total[5m]) * 100"
          legendFormat: "Error Rate %"
    
    - title: "Availability"
      type: "singlestat"
      targets:
        - expr: "rate(http_requests_total{status=~'2..'}[5m]) / rate(http_requests_total[5m]) * 100"
          legendFormat: "Availability %"
    
    - title: "Global Latency Heatmap"
      type: "heatmap"
      targets:
        - expr: "http_request_duration_seconds_bucket"
          legendFormat: "{{ country }}"
    
    - title: "SSE Connections"
      type: "graph"
      targets:
        - expr: "sse_connections_active"
          legendFormat: "Active SSE Connections"
        - expr: "rate(sse_connections_total[5m])"
          legendFormat: "New Connections/sec"
```

### å‘Šè­¦è§„åˆ™é…ç½®

```yaml
# alerting-rules.yml
groups:
  - name: "aws-mcp-performance"
    rules:
      - alert: "HighResponseTime"
        expr: "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.2"
        for: "5m"
        labels:
          severity: "warning"
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }}s"
      
      - alert: "HighErrorRate"
        expr: "rate(http_requests_total{status=~'5..'}[5m]) / rate(http_requests_total[5m]) > 0.01"
        for: "2m"
        labels:
          severity: "critical"
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }}"
      
      - alert: "LowAvailability"
        expr: "rate(http_requests_total{status=~'2..'}[5m]) / rate(http_requests_total[5m]) < 0.999"
        for: "5m"
        labels:
          severity: "critical"
        annotations:
          summary: "Low availability detected"
          description: "Availability is {{ $value | humanizePercentage }}"
      
      - alert: "TooManySSEConnections"
        expr: "sse_connections_active > 10000"
        for: "1m"
        labels:
          severity: "warning"
        annotations:
          summary: "High number of SSE connections"
          description: "{{ $value }} active SSE connections"
```

## ğŸ” æ€§èƒ½åˆ†æå·¥å…·

### 1. æ€§èƒ½ç“¶é¢ˆåˆ†æè„šæœ¬

```javascript
// scripts/performance-analyzer.js
const fs = require('fs');
const path = require('path');

class PerformanceAnalyzer {
  constructor(dataDir) {
    this.dataDir = dataDir;
  }

  analyze() {
    console.log('ğŸ” åˆ†ææ€§èƒ½æ•°æ®...');
    
    const files = fs.readdirSync(this.dataDir).filter(f => f.endsWith('.json'));
    const analysis = {
      summary: {},
      bottlenecks: [],
      recommendations: []
    };

    files.forEach(file => {
      const data = JSON.parse(fs.readFileSync(path.join(this.dataDir, file)));
      this.analyzeTestRun(data, analysis);
    });

    this.generateRecommendations(analysis);
    this.generateReport(analysis);

    return analysis;
  }

  analyzeTestRun(data, analysis) {
    // åˆ†æå“åº”æ—¶é—´åˆ†å¸ƒ
    const responseTimes = data.metrics?.http_req_duration?.values || [];
    if (responseTimes.length > 0) {
      const p50 = this.percentile(responseTimes, 50);
      const p95 = this.percentile(responseTimes, 95);
      const p99 = this.percentile(responseTimes, 99);

      analysis.summary.responseTime = { p50, p95, p99 };

      // è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
      if (p95 > 500) {
        analysis.bottlenecks.push({
          type: 'High Response Time',
          severity: 'high',
          value: p95,
          description: `P95 response time (${p95}ms) exceeds target (200ms)`
        });
      }
    }

    // åˆ†æé”™è¯¯ç‡
    const errorRate = data.metrics?.http_req_failed?.rate || 0;
    analysis.summary.errorRate = errorRate;

    if (errorRate > 0.01) {
      analysis.bottlenecks.push({
        type: 'High Error Rate',
        severity: 'critical',
        value: errorRate,
        description: `Error rate (${(errorRate * 100).toFixed(2)}%) exceeds target (1%)`
      });
    }

    // åˆ†æååé‡
    const throughput = data.metrics?.iterations?.rate || 0;
    analysis.summary.throughput = throughput;

    if (throughput < 100) {
      analysis.bottlenecks.push({
        type: 'Low Throughput',
        severity: 'medium',
        value: throughput,
        description: `Throughput (${throughput} req/s) below expected (>1000 req/s)`
      });
    }
  }

  generateRecommendations(analysis) {
    analysis.bottlenecks.forEach(bottleneck => {
      switch (bottleneck.type) {
        case 'High Response Time':
          analysis.recommendations.push({
            priority: 'high',
            action: 'Optimize API response time',
            details: [
              'Implement caching for AWS documentation',
              'Optimize HTML to Markdown conversion',
              'Use Cloudflare Workers KV for frequent requests',
              'Enable compression for large responses'
            ]
          });
          break;

        case 'High Error Rate':
          analysis.recommendations.push({
            priority: 'critical',
            action: 'Reduce error rate',
            details: [
              'Improve error handling and retry logic',
              'Add input validation for all parameters',
              'Implement graceful degradation for AWS API failures',
              'Add circuit breaker for external dependencies'
            ]
          });
          break;

        case 'Low Throughput':
          analysis.recommendations.push({
            priority: 'medium',
            action: 'Increase throughput capacity',
            details: [
              'Optimize Workers runtime performance',
              'Implement request batching where possible',
              'Review and optimize async/await patterns',
              'Consider parallel processing for multiple docs'
            ]
          });
          break;
      }
    });
  }

  generateReport(analysis) {
    const report = `
# æ€§èƒ½åˆ†ææŠ¥å‘Š

## ğŸ“Š æ€§èƒ½æ‘˜è¦
- **å“åº”æ—¶é—´**: P50=${analysis.summary.responseTime?.p50}ms, P95=${analysis.summary.responseTime?.p95}ms, P99=${analysis.summary.responseTime?.p99}ms
- **é”™è¯¯ç‡**: ${(analysis.summary.errorRate * 100).toFixed(2)}%
- **ååé‡**: ${analysis.summary.throughput} req/s

## ğŸš¨ å‘ç°çš„ç“¶é¢ˆ
${analysis.bottlenecks.map(b => `
### ${b.type} (${b.severity})
- **æ•°å€¼**: ${b.value}
- **æè¿°**: ${b.description}
`).join('')}

## ğŸ’¡ ä¼˜åŒ–å»ºè®®
${analysis.recommendations.map((r, i) => `
### ${i + 1}. ${r.action} (ä¼˜å…ˆçº§: ${r.priority})
${r.details.map(d => `- ${d}`).join('\n')}
`).join('')}

## ğŸ“ˆ æ€§èƒ½è¶‹åŠ¿
[å›¾è¡¨å ä½ç¬¦ - éœ€è¦é›†æˆå®é™…å›¾è¡¨ç”Ÿæˆ]

---
ç”Ÿæˆæ—¶é—´: ${new Date().toISOString()}
`;

    fs.writeFileSync(path.join(this.dataDir, 'performance-analysis.md'), report);
    console.log('âœ… æ€§èƒ½åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ');
  }

  percentile(arr, p) {
    if (!arr.length) return 0;
    const sorted = arr.sort((a, b) => a - b);
    const index = Math.ceil(sorted.length * p / 100) - 1;
    return sorted[index];
  }
}

module.exports = { PerformanceAnalyzer };
```

### 2. å®æ—¶æ€§èƒ½ç›‘æ§ä¸­é—´ä»¶

```typescript
// src/middleware/performance.ts
export interface PerformanceMetrics {
  requestCount: number;
  errorCount: number;
  totalResponseTime: number;
  averageResponseTime: number;
  p95ResponseTime: number;
  activeConnections: number;
  memoryUsage: number;
}

export class RealTimePerformanceMonitor {
  private metrics: PerformanceMetrics = {
    requestCount: 0,
    errorCount: 0,
    totalResponseTime: 0,
    averageResponseTime: 0,
    p95ResponseTime: 0,
    activeConnections: 0,
    memoryUsage: 0
  };

  private responseTimes: number[] = [];
  private readonly maxSamples = 1000;

  middleware() {
    return async (c: Context, next: () => Promise<void>) => {
      const startTime = performance.now();
      this.metrics.requestCount++;
      
      try {
        await next();
        
        const responseTime = performance.now() - startTime;
        this.recordResponseTime(responseTime);
        
        // å®æ—¶æ€§èƒ½æ•°æ®æ”¶é›†
        c.header('X-Performance-Metrics', JSON.stringify({
          responseTime: responseTime.toFixed(2),
          requestCount: this.metrics.requestCount,
          averageResponseTime: this.metrics.averageResponseTime.toFixed(2),
          p95ResponseTime: this.metrics.p95ResponseTime.toFixed(2)
        }));
        
      } catch (error) {
        this.metrics.errorCount++;
        throw error;
      }
    };
  }

  recordResponseTime(time: number) {
    this.responseTimes.push(time);
    
    // ä¿æŒå›ºå®šæ ·æœ¬æ•°é‡
    if (this.responseTimes.length > this.maxSamples) {
      this.responseTimes.shift();
    }
    
    // æ›´æ–°ç»Ÿè®¡æ•°æ®
    this.metrics.totalResponseTime += time;
    this.metrics.averageResponseTime = this.metrics.totalResponseTime / this.metrics.requestCount;
    this.metrics.p95ResponseTime = this.calculatePercentile(this.responseTimes, 95);
  }

  calculatePercentile(arr: number[], percentile: number): number {
    if (arr.length === 0) return 0;
    const sorted = [...arr].sort((a, b) => a - b);
    const index = Math.ceil(sorted.length * percentile / 100) - 1;
    return sorted[Math.max(0, index)];
  }

  getMetrics(): PerformanceMetrics {
    return { ...this.metrics };
  }

  getDetailedReport() {
    const now = new Date();
    return {
      timestamp: now.toISOString(),
      metrics: this.getMetrics(),
      responseTimeDistribution: {
        min: Math.min(...this.responseTimes) || 0,
        max: Math.max(...this.responseTimes) || 0,
        p50: this.calculatePercentile(this.responseTimes, 50),
        p90: this.calculatePercentile(this.responseTimes, 90),
        p95: this.calculatePercentile(this.responseTimes, 95),
        p99: this.calculatePercentile(this.responseTimes, 99)
      },
      healthStatus: this.getHealthStatus()
    };
  }

  getHealthStatus() {
    const errorRate = this.metrics.requestCount > 0 ? 
      this.metrics.errorCount / this.metrics.requestCount : 0;
    
    if (errorRate > 0.05 || this.metrics.p95ResponseTime > 1000) {
      return 'unhealthy';
    } else if (errorRate > 0.01 || this.metrics.p95ResponseTime > 500) {
      return 'degraded';
    } else {
      return 'healthy';
    }
  }

  reset() {
    this.metrics = {
      requestCount: 0,
      errorCount: 0,
      totalResponseTime: 0,
      averageResponseTime: 0,
      p95ResponseTime: 0,
      activeConnections: 0,
      memoryUsage: 0
    };
    this.responseTimes = [];
  }
}
```

## ğŸ“‹ æ€§èƒ½ä¼˜åŒ–æ¸…å•

### åº”ç”¨å±‚ä¼˜åŒ–

- [ ] **ç¼“å­˜ç­–ç•¥**
  - [ ] å®ç°AWSæ–‡æ¡£å†…å®¹ç¼“å­˜
  - [ ] ä½¿ç”¨Cloudflare Workers KVå­˜å‚¨
  - [ ] è®¾ç½®åˆé€‚çš„ç¼“å­˜è¿‡æœŸæ—¶é—´
  - [ ] å®ç°ç¼“å­˜é¢„çƒ­æœºåˆ¶

- [ ] **ä»£ç ä¼˜åŒ–**
  - [ ] ä¼˜åŒ–HTMLåˆ°Markdownè½¬æ¢ç®—æ³•
  - [ ] ä½¿ç”¨æµå¼å¤„ç†å¤§æ–‡æ¡£
  - [ ] å®ç°è¯·æ±‚å»é‡æœºåˆ¶
  - [ ] ä¼˜åŒ–æ­£åˆ™è¡¨è¾¾å¼æ€§èƒ½

- [ ] **è¿æ¥ä¼˜åŒ–**
  - [ ] å®ç°è¿æ¥æ± ç®¡ç†
  - [ ] ä¼˜åŒ–SSEè¿æ¥ä¿æ´»
  - [ ] å®ç°æ™ºèƒ½é‡è¿ç­–ç•¥
  - [ ] æ·»åŠ è¿æ¥é™æµæœºåˆ¶

### ç½‘ç»œå±‚ä¼˜åŒ–

- [ ] **CDNé…ç½®**
  - [ ] å¯ç”¨Cloudflareçš„æ‰€æœ‰æ€§èƒ½ä¼˜åŒ–
  - [ ] é…ç½®æ™ºèƒ½è·¯ç”±
  - [ ] å¯ç”¨HTTP/3æ”¯æŒ
  - [ ] ä¼˜åŒ–ç¼“å­˜è§„åˆ™

- [ ] **å‹ç¼©ä¼˜åŒ–**
  - [ ] å¯ç”¨Gzip/Brotliå‹ç¼©
  - [ ] ä¼˜åŒ–JSONå“åº”å¤§å°
  - [ ] å®ç°å¢é‡æ›´æ–°æœºåˆ¶
  - [ ] ä½¿ç”¨äºŒè¿›åˆ¶åè®®ä¼ è¾“

### ç›‘æ§å±‚ä¼˜åŒ–

- [ ] **å®æ—¶ç›‘æ§**
  - [ ] å®ç°æ€§èƒ½æŒ‡æ ‡å®æ—¶æ”¶é›†
  - [ ] è®¾ç½®æ€§èƒ½å‘Šè­¦é˜ˆå€¼
  - [ ] å»ºç«‹æ€§èƒ½è¶‹åŠ¿åˆ†æ
  - [ ] å®ç°å¼‚å¸¸æ£€æµ‹ç®—æ³•

---

**ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•å’Œç›‘æ§æ–¹æ¡ˆè®¾è®¡å®Œæˆï¼æ¥ä¸‹æ¥åˆ¶å®šé£é™©è¯„ä¼°å’Œåº”æ€¥é¢„æ¡ˆã€‚**